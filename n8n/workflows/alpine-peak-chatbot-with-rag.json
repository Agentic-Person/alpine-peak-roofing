{
  "name": "alpine-peak-chatbot-with-rag",
  "nodes": [
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {}
      },
      "id": "16420381-a6df-4eef-99c0-a4554dd3b05b",
      "name": "Webhook Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.5,
      "position": [
        1680,
        0
      ],
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// Extract and validate chat message data\\nfor (const item of $input.all()) {\\n  const inputData = item.json;\\n  \\n  // Validate required fields\\n  if (!inputData.message) {\\n    throw new Error('Message is required');\\n  }\\n  \\n  // Extract context and user data\\n  const chatData = {\\n    message: inputData.message,\\n    session_id: inputData.session_id || 'session_' + Date.now(),\\n    page_context: inputData.page_context || 'website',\\n    user_data: inputData.user_data || {},\\n    timestamp: new Date().toISOString(),\\n    ip_address: 'unknown'\\n  };\\n  \\n  // Determine message intent\\n  const message = inputData.message.toLowerCase();\\n  let intent = 'general';\\n  let priority = 'normal';\\n  \\n  // Intent classification\\n  if (message.includes('estimate') || message.includes('quote') || message.includes('price')) {\\n    intent = 'estimation_request';\\n    priority = 'high';\\n  } else if (message.includes('emergency') || message.includes('urgent') || message.includes('leak')) {\\n    intent = 'emergency';\\n    priority = 'urgent';\\n  } else if (message.includes('schedule') || message.includes('appointment') || message.includes('inspection')) {\\n    intent = 'scheduling';\\n    priority = 'high';\\n  } else if (message.includes('material') || message.includes('shingle') || message.includes('warranty')) {\\n    intent = 'product_inquiry';\\n    priority = 'normal';\\n  } else if (message.includes('contact') || message.includes('phone') || message.includes('email')) {\\n    intent = 'contact_info';\\n    priority = 'normal';\\n  }\\n  \\n  // Add classification to data\\n  chatData.intent = intent;\\n  chatData.priority = priority;\\n  \\n  return { json: chatData };\\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        240,
        0
      ],
      "id": "20d5bb13-1349-4be7-9c7c-cf377374babb",
      "name": "Message Processing",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// Generate query embedding for vector search\\nconst axios = require('axios');\\n\\nfor (const item of $input.all()) {\\n  const data = item.json;\\n  \\n  try {\\n    // Prepare enhanced query for embedding\\n    let enhancedQuery = data.message;\\n    \\n    // Add context based on intent\\n    if (data.intent === 'emergency') {\\n      enhancedQuery += ' emergency repair storm damage leak';\\n    } else if (data.intent === 'estimation_request') {\\n      enhancedQuery += ' cost estimate materials installation';\\n    } else if (data.intent === 'product_inquiry') {\\n      enhancedQuery += ' materials roofing products';\\n    }\\n    \\n    // Add location context\\n    enhancedQuery += ' Denver Colorado mountain climate';\\n    \\n    // Call OpenAI embeddings API\\n    const response = await axios.post(\\n      'https://api.openai.com/v1/embeddings',\\n      {\\n        model: 'text-embedding-ada-002',\\n        input: enhancedQuery,\\n        encoding_format: 'float'\\n      },\\n      {\\n        headers: {\\n          'Authorization': 'Bearer ' + $vars.OPENAI_API_KEY,\\n          'Content-Type': 'application/json'\\n        },\\n        timeout: 30000\\n      }\\n    );\\n    \\n    const embedding = response.data.data[0].embedding;\\n    \\n    return {\\n      json: {\\n        ...data,\\n        query_embedding: embedding,\\n        enhanced_query: enhancedQuery,\\n        embedding_tokens: response.data.usage.total_tokens\\n      }\\n    };\\n    \\n  } catch (error) {\\n    console.error('Embedding generation failed:', error.message);\\n    \\n    // Return original data without embedding for fallback\\n    return {\\n      json: {\\n        ...data,\\n        query_embedding: null,\\n        enhanced_query: data.message,\\n        embedding_error: error.message\\n      }\\n    };\\n  }\\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        480,
        0
      ],
      "id": "embedding-generator-001",
      "name": "Generate Query Embedding",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.NEXT_PUBLIC_SUPABASE_URL }}/rest/v1/rpc/search_knowledge_base",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendHeaders": true,
        "specifyHeaders": "keypair",
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer {{ $vars.SUPABASE_SERVICE_ROLE_KEY }}"
            },
            {
              "name": "apikey",
              "value": "{{ $vars.SUPABASE_SERVICE_ROLE_KEY }}"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"query_embedding\": {{ JSON.stringify($json.query_embedding) }},\n  \"query_text\": {{ JSON.stringify($json.message) }},\n  \"match_threshold\": {{ $json.priority === 'urgent' ? 0.70 : 0.78 }},\n  \"match_count\": {{ $json.intent === 'emergency' ? 3 : 5 }},\n  \"filter_category\": {{ $json.intent === 'emergency' ? null : ($json.intent === 'product_inquiry' ? 'materials' : null) }},\n  \"filter_urgency\": {{ $json.intent === 'emergency' ? 'emergency' : null }}\n}",
        "options": {
          "timeout": 10000,
          "response": {
            "response": {
              "neverError": true
            }
          }
        }
      },
      "id": "vector-search-001",
      "name": "Vector Knowledge Search",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        720,
        0
      ],
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// Process vector search results and build context\\nfor (const item of $input.all()) {\\n  const searchResponse = item.json;\\n  const originalData = $node['Generate Query Embedding'].json;\\n  \\n  let retrievedContext = '';\\n  let contextSources = [];\\n  let totalTokens = 0;\\n  const maxContextTokens = 2000;\\n  \\n  try {\\n    // Check if we have valid search results\\n    if (searchResponse && Array.isArray(searchResponse) && searchResponse.length > 0) {\\n      console.log('Found', searchResponse.length, 'knowledge base results');\\n      \\n      // Sort by similarity and relevance\\n      const sortedResults = searchResponse\\n        .filter(result => result.similarity > 0.75) // Only high-quality matches\\n        .sort((a, b) => {\\n          // Prioritize by urgency first, then similarity\\n          const urgencyOrder = { 'emergency': 1, 'urgent': 2, 'high': 3, 'normal': 4 };\\n          const aUrgency = urgencyOrder[result.metadata?.urgency] || 5;\\n          const bUrgency = urgencyOrder[result.metadata?.urgency] || 5;\\n          \\n          if (aUrgency !== bUrgency) return aUrgency - bUrgency;\\n          return b.similarity - a.similarity;\\n        });\\n      \\n      // Build context from top results\\n      for (const result of sortedResults) {\\n        const resultTokens = result.tokens || 0;\\n        \\n        if (totalTokens + resultTokens <= maxContextTokens) {\\n          // Add section header\\n          const category = result.metadata?.category || 'General';\\n          const title = result.title || 'Knowledge Base Content';\\n          \\n          retrievedContext += `## ${category.toUpperCase()}: ${title}\\n`;\\n          retrievedContext += `${result.content}\\n\\n`;\\n          \\n          contextSources.push({\\n            id: result.id,\\n            title: result.title,\\n            category: result.metadata?.category,\\n            similarity: Math.round(result.similarity * 100) / 100,\\n            tokens: resultTokens\\n          });\\n          \\n          totalTokens += resultTokens;\\n        } else {\\n          break; // Stop if we'd exceed token limit\\n        }\\n      }\\n      \\n      console.log('Built context with', contextSources.length, 'sources,', totalTokens, 'tokens');\\n    } else {\\n      console.log('No valid search results found');\\n    }\\n  } catch (error) {\\n    console.error('Error processing search results:', error.message);\\n  }\\n  \\n  // Add fallback context if no good matches found\\n  if (!retrievedContext.trim()) {\\n    retrievedContext = `## ALPINE PEAK ROOFING OVERVIEW\\n` +\\n      `Alpine Peak Roofing has served Denver and surrounding mountain communities for 25+ years. ` +\\n      `We specialize in residential and commercial roofing with expertise in Colorado's unique climate challenges. ` +\\n      `Our services include asphalt shingles, metal roofing, tile systems, emergency repairs, and comprehensive inspections. ` +\\n      `Call (970) 446-8995 for immediate assistance or schedule a free inspection.\\n\\n`;\\n    \\n    contextSources.push({\\n      id: 'fallback',\\n      title: 'Company Overview',\\n      category: 'general',\\n      similarity: 1.0,\\n      tokens: 100\\n    });\\n  }\\n  \\n  return {\\n    json: {\\n      ...originalData,\\n      retrieved_context: retrievedContext,\\n      context_sources: contextSources,\\n      total_context_tokens: totalTokens,\\n      search_results_count: searchResponse?.length || 0\\n    }\\n  };\\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        960,
        0
      ],
      "id": "context-builder-001",
      "name": "Build RAG Context",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "You are Sarah, the AI assistant for Alpine Peak Roofing, Denver's premier roofing contractor with 25+ years of experience serving the Denver Metro Area and mountain communities.\\n\\nCOMPANY DETAILS:\\n- Business Name: Alpine Peak Roofing\\n- Location: Denver, Colorado  \\n- Phone: (970) 446-8995\\n- Tagline: \\\"Pinnacle of Protection, Peak of Performance\\\"\\n- Services: Residential & Commercial Roofing, Emergency Repairs, Inspections\\n- Specialties: All roofing materials and Colorado climate expertise\\n\\nCURRENT CONVERSATION CONTEXT:\\nUser Message: {{ $json.message }}\\nIntent: {{ $json.intent }}\\nPriority: {{ $json.priority }}\\nPage Context: {{ $json.page_context }}\\n\\nRELEVANT KNOWLEDGE (Retrieved from knowledge base):\\n{{ $json.retrieved_context }}\\n\\nKnowledge Sources Used: {{ $json.context_sources.length }} sources with {{ $json.total_context_tokens }} tokens\\n\\nRESPONSE GUIDELINES:\\n\\n1. **Use Retrieved Knowledge**: Base your response primarily on the retrieved knowledge above. This contains the most current and detailed information about Alpine Peak's services, expertise, and processes.\\n\\n2. **Priority-Based Response**:\\n   - URGENT/EMERGENCY: Immediate safety assessment, direct to call (970) 446-8995\\n   - HIGH (estimates/scheduling): Provide detailed information, guide to booking\\n   - NORMAL: Educational response with relevant details, suggest inspection\\n\\n3. **Professional Tone**: Knowledgeable, helpful, solution-focused\\n\\n4. **Colorado Expertise**: Reference Denver climate, altitude effects, hail seasons, snow loads, local regulations when relevant\\n\\n5. **Clear Call-to-Action**:\\n   - Emergencies: \\\"Call (970) 446-8995 immediately\\\"\\n   - Estimates: \\\"Schedule your free inspection and estimate\\\"\\n   - General: \\\"Let us assess your roof's condition with a free inspection\\\"\\n\\n6. **Safety First**: Always prioritize customer safety, especially for emergency situations\\n\\nProvide a helpful, professional response that demonstrates Alpine Peak's expertise while guiding the user toward the appropriate next step. Use the retrieved knowledge to give specific, accurate information about materials, techniques, costs, or processes when available.\\n\\nKeep responses conversational but informative, typically 2-4 sentences unless more detail is specifically requested."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        1200,
        0
      ],
      "id": "rag-ai-agent-001",
      "name": "RAG-Enhanced AI Agent",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o-mini"
        },
        "options": {
          "temperature": 0.7,
          "maxTokens": 500,
          "topP": 0.9
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        1072,
        240
      ],
      "id": "60cf24d8-1d43-4d6a-9098-b202bbef1853",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "od3qrZGbVE2RSz7J",
          "name": "OpenAi APS account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "alpine-peak-chatbot-rag",
        "responseMode": "responseNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2.1,
      "position": [
        -32,
        0
      ],
      "id": "60efb47c-ba54-4216-bb32-b2cad5045e67",
      "name": "Webhook",
      "webhookId": "4759e00b-fadb-4678-9c62-ceed60ebcd55",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1.3,
      "position": [
        1264,
        224
      ],
      "id": "da30db74-3242-4e66-afe9-6165bcc5504b",
      "name": "Postgres Chat Memory",
      "credentials": {
        "postgres": {
          "id": "OYphI3uul5xfR5wF",
          "name": "Postgres APS"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// Format final response with context metadata\\nfor (const item of $input.all()) {\\n  const data = item.json;\\n  \\n  let responseMessage = 'Thank you for your message. We will get back to you soon.';\\n  \\n  // Try to get AI response from agent output\\n  if (data.output) {\\n    responseMessage = data.output;\\n  } else if (data.text) {\\n    responseMessage = data.text;\\n  } else if (data.message) {\\n    responseMessage = data.message;\\n  }\\n  \\n  // Get context information from the RAG context builder\\n  const contextData = $node['Build RAG Context'].json;\\n  \\n  const result = {\\n    success: true,\\n    message: responseMessage,\\n    timestamp: new Date().toISOString(),\\n    metadata: {\\n      intent: contextData.intent,\\n      priority: contextData.priority,\\n      context_sources_used: contextData.context_sources?.length || 0,\\n      total_context_tokens: contextData.total_context_tokens || 0,\\n      search_results_found: contextData.search_results_count || 0,\\n      embedding_tokens: contextData.embedding_tokens || 0,\\n      rag_enhanced: contextData.context_sources?.length > 0\\n    }\\n  };\\n  \\n  return { json: result };\\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1440,
        0
      ],
      "id": "response-formatter-001",
      "name": "Format Enhanced Response",
      "onError": "continueRegularOutput"
    }
  ],
  "pinData": {},
  "connections": {
    "Message Processing": {
      "main": [
        [
          {
            "node": "Generate Query Embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Query Embedding": {
      "main": [
        [
          {
            "node": "Vector Knowledge Search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Vector Knowledge Search": {
      "main": [
        [
          {
            "node": "Build RAG Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build RAG Context": {
      "main": [
        [
          {
            "node": "RAG-Enhanced AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "RAG-Enhanced AI Agent": {
      "main": [
        [
          {
            "node": "Format Enhanced Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Enhanced Response": {
      "main": [
        [
          {
            "node": "Webhook Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "RAG-Enhanced AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Postgres Chat Memory": {
      "ai_memory": [
        [
          {
            "node": "RAG-Enhanced AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Webhook": {
      "main": [
        [
          {
            "node": "Message Processing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "enhanced-rag-v1",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "62eb072701814b1a1a9c022b7a751c5f8dac0a37a5a414c436048bc8706d2f6f"
  },
  "id": "AlpinePeakRAG",
  "tags": ["rag", "vector-search", "chatbot", "knowledge-base"]
}